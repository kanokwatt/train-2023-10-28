{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1HWpAYA_6V8B7nzHD2NCFK1ZWYFegf1A6","timestamp":1698406141765}],"authorship_tag":"ABX9TyNwvpI5oggNntUhu8s1pym+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## การจำแนกข้อมูล (Classification with K-Fold Cross Validation and Ensemble): Supervised Learning"],"metadata":{"id":"XxDg7zb_Pbil"}},{"cell_type":"markdown","source":["### Step 1: การจัดเตรียมข้อมูล"],"metadata":{"id":"r4vymW2I9c5J"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JYwH5Z5ZZzDS"},"outputs":[],"source":["# https://levelup.gitconnected.com/advanced-seaborn-demystifying-the-complex-plots-537582977c8c\n","\n","import seaborn as sns\n","\n","data = sns.load_dataset(\"iris\")  # ข้อมูลดอกไอริส\n","?"]},{"cell_type":"markdown","source":["### Step 2: Data Visualization"],"metadata":{"id":"ZCUV-7o_5-vu"}},{"cell_type":"code","source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","\n","sns.set(style=\"ticks\")\n","sns.pairplot(?, ?, markers=[\"o\", \"s\", \"D\"])  # Pair Plot เพื่อแสดงความสัมพันธ์ระหว่างคอลัมน์ต่าง ๆ โดยกำหนดสี ด้วยผลเฉลยของ สปีชีย์ (hue=\"species\")\n","\n","plt.show()"],"metadata":{"id":"2-ggeH-g7vTV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 3: Data Encoding\n","\n","ทำการแปลงข้อมูลผลเฉลย (Target/Label/Answer) คือ สปีชีย์ (species) ให้เป็นตัวเลข ด้วย Label Encoding"],"metadata":{"id":"7BngiO6B8gIw"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn import preprocessing                 # นำเข้า Library ที่จำเป็นในการจัดเตรียมข้อมูล\n","\n","label_encoder = ?     # สร้างตัวแปรที่จะทำหน้าที่เข้ารหัส (label_encoder) จาก sklearn.preprocessing\n","data['species'] = pd.DataFrame(label_encoder.fit_transform(?)) # ทำการแปลงคอลัมน์สปีชีย์ (species) ด้วยวิธีการ Label Encoding แล้วเขียนทับลงคอลัมน์เดิม\n","\n","data"],"metadata":{"id":"WAxCtOo-8j5Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 4: คำนวณความสัมพันธ์ของตัวแปร ด้วย Correlation\n","\n","Feature Selection: เราจะทราบได้อย่างไร? ว่าควรเลือกคอลัมน์ใดมาใช้ในการเรียนรู้ (Train)\n","\n","1. sepal length (cm)\n","2. sepal width (cm)\n","3. petal length (cm)\n","4. petal width (cm)\n"],"metadata":{"id":"sJ5aRlLs8Ia4"}},{"cell_type":"code","source":["?  # คำนวณค่าความสัมพันธ์(correlation) ระหว่างตัวแปรของข้อมูล (data)"],"metadata":{"id":"ADBXoXuT8QRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.heatmap(?, annot=True) # แสดงผลของค่าความสัมพันธ์ ระหว่างตัวแปร ด้วย Heat Map"],"metadata":{"id":"TwaaiH5u9GEL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 5: สร้างแบบจำลอง (Model)"],"metadata":{"id":"y6wANP6qbOXz"}},{"cell_type":"code","source":["from sklearn import model_selection\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import RandomForestClassifier\n","\n","clf1 = LogisticRegression(random_state=1)\n","clf2 = GaussianNB()\n","clf3 = RandomForestClassifier(random_state=1)"],"metadata":{"id":"0cqE0SFgbKpO","executionInfo":{"status":"ok","timestamp":1698464901414,"user_tz":-420,"elapsed":487,"user":{"displayName":"กนกวรรธน์ เซี่ยงเจ็น","userId":"06075188454127765267"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Step 6: K-Fold Cross Validation (ฝึกสอนโดยแบ่งข้อมูลเป็น K ส่วน)"],"metadata":{"id":"ZvqYVktVbvpS"}},{"cell_type":"code","source":["# กำหนดให้ [sepal_width, petal_length] เป็นข้อมูลฝึกสอน (Train) / ลองเปลี่ยนเป็น [petal_length, petal_width]\n","column_names = ['sepal_width','petal_length']\n","\n","X, y = ?, ?"],"metadata":{"id":"I4pEMXSFasF6","executionInfo":{"status":"ok","timestamp":1698464901414,"user_tz":-420,"elapsed":6,"user":{"displayName":"กนกวรรธน์ เซี่ยงเจ็น","userId":"06075188454127765267"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print('5-Fold Cross Validation')\n","\n","techniques = ['Logistic Regression', 'Naive Bayes', 'Random Forest'] # เทคนิคที่ใช้ในการสร้างแบบจำลอง\n","\n","for clf, technique in zip([clf1, clf2, clf3], techniques):\n","  scores = model_selection.cross_val_score(clf, X, y, cv=?, scoring='accuracy') # cv=K คือจำนวนของการแบ่ง K-Fold เช่น 5-Fold\n","\n","  print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), technique)) # คำนวณค่าเฉลี่ย / ส่วนเบี่ยงเบนมาตรฐาน / ของแต่ละแบบจำลอง"],"metadata":{"id":"NTBIf3iSbySU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 7: Ensemble Voting\n","\n","เป็นเทคนิคที่นำเลือก ผลการทำนาย ที่ดีที่สุด จากหลายแบบจำลอง (Multiple Model)\n"],"metadata":{"id":"Mep5D2QyErVi"}},{"cell_type":"code","source":["#------------------------------------------------------------------------\n","# แก้ปัญหา Dependency ของ sklearn.externals ที่ Deprecated ไป\n","#------------------------------------------------------------------------\n","import six\n","import sys\n","\n","sys.modules['sklearn.externals.six'] = six\n","#------------------------------------------------------------------------\n","\n","from mlxtend.classifier import ? # EnsembleVoteClassifier\n","\n","eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1, 1, 1]) # ลองเปลี่ยนค่า weights อยู่ระหว่าง [0-1]\n","\n","techniques = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'Ensemble'] # เทคนิคที่ใช้ในการสร้างแบบจำลอง\n","\n","for clf, technique in zip([clf1, clf2, clf3, eclf], techniques):\n","  scores = model_selection.cross_val_score(clf, X, y, cv=5, scoring='accuracy') # cv=K คือจำนวนของการแบ่ง K-Fold\n","\n","  print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), technique)) # คำนวณค่าเฉลี่ย / ส่วนเบี่ยงเบนมาตรฐาน / ของแต่ละแบบจำลอง\n"],"metadata":{"id":"fQs65_8vFHUo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 8: Data Visualization\n"],"metadata":{"id":"34bSvWDVG27i"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","import itertools\n","from mlxtend.plotting import ? # plot_decision_regions\n","\n","gs = gridspec.GridSpec(2, 2)\n","\n","fig = plt.figure(figsize=(10, 10))\n","\n","techniques = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'Ensemble'] # เทคนิคที่ใช้ในการสร้างแบบจำลอง\n","\n","for clf, lab, grd in zip([clf1, clf2, clf3, eclf],\n","                                techniques,\n","                                itertools.product([0, 1], repeat=2)):\n","    clf.fit(?, ?) # ระบุค่าที่ต้องการนำไปฝึก (X, y)\n","    ax = plt.subplot(gs[grd[0], grd[1]])\n","\n","    fig = plot_decision_regions(X=?, y=?, clf=?)  # ระบุข้อมูลที่ต้องใช้ในการแสดงกราฟ X, y, clf\n","    plt.title(lab)"],"metadata":{"id":"CVDdwXNAG2W3"},"execution_count":null,"outputs":[]}]}